---
title: "Assignment 3: Model comparison"
author: "Eszter Pal√≥cz"
output: html_document
editor_options: 
  chunk_output_type: console
---

In this lab assignment you are going to work with (simulated) data related to perioperative pain and its psychological and hormonal predictors. In the assignment you will assess the added benefit of including some psychological and hormonal predictors to the already established demographic predictors of pain.

In this assignment you will set up a hierarchical regression model to predict postoperative pain after wisdom tooth surgery. 

# Research problem

The amount of pain experienced around and after surgeries are highly variable between and within individuals. In order to improve surgical pain management regimens we need to understand what influences pain around surgical procedures and predict the amount of pain an individual will experience.

Your first study in this area is related to assessing the influence of trait and state psychological measures on pain, and to see whether taking into account these variables can improve our understanding of postoperative pain.

# Procedures and measures

Use the data file called ‚Äòassignment_3_dataset‚Äô, from the 'data/' folder.

You have collected data from 160 adults who were scheduled to undergo surgical extraction of the third mandibular molar (wisdom tooth surgery). Patients filled out a form in the waiting room before their surgery. The form contained questions about their sex, age, and weight, and psychological questionnaires assessing anxiety, pain catastrophizing, and mindfulness (see descriptions below). You also got blood samples and saliva samples from participants in the waiting room 5 minutes before their operations to determine the serum (a component of the blood) and salivary cortisol levels of participants. Participants were contacted 5 hours after the surgery to see how much pain they were experiencing. The __level of pain__ at that moment was recorded using a numerical rating scale using a __scale of 0 to 10__, where 0 means ‚Äúno pain‚Äù and 10 means ‚Äúworst pain I can imagine‚Äù. 

__The State Trait Anxiety Inventory:__ T measures trait anxiety on a scale of 20 to 80, higher scores mean higher anxiety. Anxiety has been found in many studies to positively correlate with the level of pain experienced. This is __variable STAI_trait__ in the dataset.

__The Pain Catastrophizing Scale__ measures the extent of pain catastrophizing, which is characterized by a tendency to magnify the threat value of a pain stimulus and to feel helpless in the presence of pain, as well as by a relative inability to prevent or inhibit pain-related thoughts in anticipation of, during, or following a painful event. The total score on this scale ranges from 0 to 52, higher scores mean higher catastrophizing. Pain catastrophizing is one of the well-established predictors of clinical pain. This is __variable pain_cat__ in the dataset.

__The Mindful Attention Awareness Scale (MAAS)__ measures dispositional mindfulness, which may be described as a tendency to turn attention to present-moment experiences in an open, non-judgmental way. The MAAS total score ranges from 1 to 6 (an average of the item scores), with higher scores representing higher dispositional mindfulness. Trait mindfulness has been theorized to serve as a protective factor against pain, as the individual would be more objective about their pain experience and tend to associate less discomfort, despair, and hopelessness to the pain-related sensations. This is __variable mindfulness__ in the dataset.

__Cortisol__ is a stress hormone associated with acute and chronic stress. Cortisol levels are thought to be positively associated with pain experience. Cortisol can be __measured from both blood and the saliva__, although, serum cortisol is often regarded in medical research as more reliably related to stress (serum is a component of the blood plasma). These are __variables cortisol_serum__, and __cortisol_saliva__ in the dataset.

# Research question

Previous studies and meta-analyses showed that age and sex are often predictors of pain (age is negatively associated with pain, while sex is a predictor more dependent on the type of the procedure). You would like to determine the extent to which taking into account psychological and hormonal variables aside from the already used demographic variables would improve our understanding of postoperative pain.

To answer this research question you will __need to compare two models__ (with a hierarchical regression). The __simpler model__ should contain __age and sex as predictors of pain__, while the __more complex model__ should contain the __predictors: age, sex, STAI, pain catastrophizing, mindfulness, and cortisol measures__. Notice that the predictors used in the simpler model are a subset of the predictors used in more complex model. __You will have to do model comparison to assess whether substantial new information was gained about pain in the more complex model compared to the simpler model.__  

# What to report

As usual, before you can interpret your model, you will need to run data and model diagnostics. First, check the variables included in the more complex model (age, sex, STAI, pain catastrophizing, mindfulness, and cortisol measures as predictors, and pain as an outcome) for __coding errors__, and the model itself for __influential outliers__ (for example using Cook‚Äôs distance). Furthermore, check the final model to see if the __assumptions of linear regression hold true__, that is, __normality__ (of the residuals), __linearity__ (of the relationship), __homogeneity of variance__ (also called homoscedasticity) and that there is no excess __multicollinearity__ (‚Äúuncorrelated predictors‚Äù in Navarro‚Äôs words). If you find anything amiss during these checks, make the appropriate decision or correction and report your findings and actions in your report. 

__Note:__ If you do any changes, such as exclude cases, or exclude predictors from the model, you will have to re-run the above checks for your final data and model.

Report the results of the simpler model and the more complex model. For both models you should report the model test statistics (adj.R2, F, df, and p value). Also, report the statistics describing the coefficients of the predictors in a table format (unstandardized regression coefficients and 95% confidence intervals, standardized regression coefficients (B and Beta values), and p values).

Write up the regression equation of the more complex model in the form of ùëå = ùëè0 + ùëè1 ‚àó X1 + ùëè2 ‚àó X2 +‚Ä¶+ bn * Xn, in which you use the actual regression coefficients of your models. (b0 stands for the intercept and b1, b2 ‚Ä¶ bn stand for the model coefficients for each of the predictors, and X1, X2, ‚Ä¶ Xn denote the predictors).

Compare the two models in terms of how much variance they explain of pain‚Äôs variability in the sample. Report Akaike information criterion (AIC) for both models and the F test statistic and p value of the likelihood ratio test comparing the two models.

# What to discuss

In your discussion of the findings, briefly interpret the results of the above analyses, and indicate whether you think that anything was gained by including the psychological and hormone measures in the model.

# Solution

## Reading the data
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(readxl)
library(tidyverse)
library(ggplot2)
library(dplyr)
library(tidyr)
library(readr)
library(stringr)
library(lmtest)
library(car)
library(knitr)

# Dataset
url <- "https://github.com/elte-ppk-r-course/Fall-2024/raw/refs/heads/main/data/assignment_3_dataset_.xlsx"

temp_file <- tempfile(fileext = ".xlsx")

download.file(url, temp_file, mode = "wb")

paindata <- read_excel(temp_file)
```

## Data and model diagnostics 

### Data diagnostics
```{r}
# Viewing the first few rows of the dataset
head(paindata)

# Checking the structure of the data (data types, missing values)
str(paindata)

# Dropping variables that are not needed for the analysis (weight, IQ, household income)
paindata <- paindata %>% dplyr::select(-weight, -IQ, -household_income)

# Checking the new dataset again
head(paindata)
str(paindata)
summary(paindata)

# Changing the variable sex to factor
paindata$sex <- as.factor(paindata$sex)

# Mindfulness scale is 1 to 6, however there is a value over 6. Filtering the values over 6
paindata <- paindata %>%
 filter(mindfulness <= 6)

summary(paindata$mindfulness)
```

```{r}
# Checking for missing values
colSums(is.na(paindata))
```

There are no missing values in the data. 

### Descriptive statistics for variables 
```{r}
# Summary (descriptive) statistics for all variables
summary(paindata)
```

## Running an exploratory data analysis (EDA) to investigate the dataset.
### Checking for the distribution of the data 
```{r}
# Histogram of numeric variables
paindata %>% 
  select_if(is.numeric) %>%  # Select numeric columns
  gather() %>%
  ggplot(aes(x=value)) + 
  geom_histogram(bins = 30, fill = "blue", alpha = 0.7) +
  facet_wrap(~key, scales = "free_x") +
  theme_minimal() +
  labs(title = "Histograms of Numeric Variables")

# Histogram of the variable sex
ggplot(paindata, aes(x = sex)) +
  geom_bar(fill = "lightblue", color = "black") +
  labs(title = "Bar Chart of Sex", x = "Sex", y = "Count") +
  theme_minimal()
```

The histograms and boxplots of variables show that there are some potential outliers 
that need to be explored further (variable: pain).

The histogram of the variable 'sex' shows that there is an element coded as "woman", 
which seems to be a coding error and needs to be put under "female". 


### Detecting outliers 
```{r}
# Boxplots to detect outliers
par(mfrow = c(2, 3))
boxplot(paindata$age, main = "Age")
boxplot(paindata$pain, main = "Pain")
boxplot(paindata$STAI_trait, main = "STAI_trait")
boxplot(paindata$pain_cat, main = "Pain Catastrophizing")
boxplot(paindata$mindfulness, main = "Mindfulness")
boxplot(paindata$cortisol_serum, main = "Cortisol Serum")
boxplot(paindata$cortisol_saliva, main = "Cortisol Saliva")
```

Further explorations with boxplots show an extreme value in the variable pain which seems 
to be a coding error. Next, influential outliers will be checked with Cook's distance.


### Checking influential outliers on the complex model
```{r}
# Fitting the complex model (age, sex, STAI_trait, pain_cat, mindfulness, cortisol_serum, cortisol_saliva)
complex_model <- lm(pain ~ age + sex + STAI_trait + pain_cat + mindfulness + cortisol_serum + cortisol_saliva, data = paindata)

# Calculating Cook's distance
cooksd <- cooks.distance(complex_model)

# Cook's distance - plot 
plot(cooksd, main = "Cook's Distance", ylab = "Cook's Distance", pch = 20)
abline(h = 4 / nrow(paindata), col = "red", lty = 2)  # Threshold line at 4/n

# Identify influential points
influential_points <- which(cooksd > (4 / nrow(paindata)))
paindata[influential_points, ]
```

As expected, it was found with Cook's distance that the variable pain includes 
an extreme value that is a coding error, therefore this value needs to be filtered (below). 


#### Correcting coding errors

```{r}
# Correcting the coding error in sex
paindata <- paindata %>%
  mutate(sex = dplyr::recode(sex, "woman" = "female"))

# Excluding the extreme value from pain that is a coding error
paindata_filtered <- paindata %>% filter(pain != 50)

# Checking new boxplot for pain
boxplot(paindata_filtered$pain, main = "Pain")
```

### Model diagnostics
#### Building the more complex model

In order to test the more complex model for outliers and to test the assumptions first build the model.

```{r}
# Fitting the model without the outlier
model_filtered <- lm(pain ~ age + sex + STAI_trait + pain_cat + mindfulness + cortisol_serum + cortisol_saliva, data = paindata_filtered)

# Model summary
summary(model_filtered)
```

#### Checking for influential outliers in the complex, filtered model

```{r}
# Calculate Cook's distance
cooksd <- cooks.distance(model_filtered)

# Plot Cook's distance
plot(cooksd, main = "Cook's Distance", ylab = "Cook's Distance", pch = 20)
abline(h = 4 / nrow(paindata), col = "red", lty = 2)  # Threshold line at 4/n

# Identify influential points
influential_points <- which(cooksd > (4 / nrow(paindata)))
paindata[influential_points, ]
```

Based on the analysis with Cook's distance, other values are not influential outliers. 

### Checking assumptions 

#### Checking the normality assumption.
```{r}
# Residuals from the complex model
residuals_complex <- residuals(model_filtered)

# Q-Q plot of residuals
qqnorm(residuals_complex)
qqline(residuals_complex, col = "red")

# Histogram of residuals
hist(residuals_complex, main = "Histogram of Residuals", xlab = "Residuals", col = "blue", breaks = 30)

# Shapiro-Wilk test
shapiro.test(residuals(model_filtered))
```

The Q-Q plot and histogram, and the results of the Shapiro-Wilk test show that the data is approximately normally distributed 
(the data points mostly follow the linear red line with some small deviations).

### Checking the linearity assumption.
```{r}
plot(model_filtered, which = 1)
```

The assumption of linearity is met. 


### Checking the homoscedasticty assumption (homogeneity of variance).

```{r}
bptest(model_filtered)

plot(model_filtered, which = 3)
```

The assumption of homoscedasticity is met.


### Checking the multicollinearity assumption.

(VIF above 5), or a VIF threshold of 3 is recommended in this paper: http://onlinelibrary.wiley.com/doi/10.1111/j.2041-210X.2009.00001.x/full

Some info about VIF: 
https://statisticalhorizons.com/multicollinearity
http://blog.minitab.com/blog/understanding-statistics/handling-multicollinearity-in-regression-analysis

```{r}
library(car)
vif(model_filtered)
```

The results of the multicollinearity check suggest that two variables (cortisol_serum and cortisol_saliva) exceed the threshold of VIF of 5, which indicates moderate to high multicollinearity between these two variables, therefore they are most likely strongly correlated with each other. In the description of the cortisol variables, it is suggested serum cortisol is found to be more reliably related to stress in medical research, therefore I will keep this variable and drop cortisol_saliva from the model. 

### Making decision based on model diagnostics

Based on the assumption tests, I decided to drop a predictor variable (cortisol_saliva). I will create the updated model. 

```{r}
# Updated model, without cortisol_saliva
model_filtered_updated <- lm(pain ~ age + sex + STAI_trait + pain_cat + mindfulness + cortisol_serum, data = paindata_filtered)

summary(model_filtered_updated)
```

#### Checking outliers of the updated model

```{r}
cooksd <- cooks.distance(model_filtered_updated)

original_data <- model_filtered_updated$model_filtered

plot(cooksd, main = "Cook's Distance", ylab = "Cook's Distance", pch = 20)
abline(h = 4 / nrow(original_data), col = "red", lty = 2)

influential_points <- which(cooksd > (4 / nrow(original_data)))
original_data[influential_points, ]
```

No influential outliers were found based on Cook's Distance. 


#### Checking assumptions of the updated model

Normality assumption

```{r}
# Calculating residuals
residuals_complex <- residuals(model_filtered_updated)

# Shapiro-Wilk test
shapiro.test(residuals(model_filtered_updated))

# Histogram of residuals
hist(residuals_complex, main = "Histogram of Residuals", xlab = "Residuals", col = "blue", breaks = 30)

# Q-Q plot of residuals
qqnorm(residuals_complex)
qqline(residuals_complex, col = "red")
```

The assumption of normality is met. 

### Linearity assumption

```{r}
plot(model_filtered_updated, which = 1)

raintest(model_filtered_updated)
```

The assumption of linearity is met. 


### Homoscedasticty assumption (homogeneity of variance)

```{r}
bptest(model_filtered_updated)

plot(model_filtered_updated, which = 3)
```

The assumption of homoscedasticity is met. 

### Multicollinearity assumption

```{r}
vif(model_filtered_updated)
```

The assumption of multicollinearity is met in the updated model. 

## Model comparison

Create the simple model and get the results of the model that needs to be reported based on the What to report section.

```{r}
simple_model <- lm(pain ~ age + sex, data = paindata_filtered)

summary(simple_model)
```

Create the more complex model based on the results of the model diagnostics. Also, get the results that needs to be reported based on the What to report section.

```{r}
complex_model_2 <- lm(pain ~ age + sex + STAI_trait + pain_cat + mindfulness + cortisol_serum, data = paindata_filtered)

summary(complex_model_2)
```

### Regression equation for the complex model
```{r}
# Extract coefficients from model2
coefs <- coef(complex_model_2)

# Round the coefficients to 3 decimal places
coefs <- round(coefs, 3)

# Create the equation string
equation <- paste("pain =", coefs[1], 
                  "+", coefs[2], "* age", 
                  "+", coefs[3], "* sex", 
                  "+", coefs[4], "* STAI_trait",
                  "+", coefs[5], "* pain_cat",
                  "+", coefs[6], "* cortisol_serum",
                  "+", coefs[7], "* mindfulness", 
                  sep = "")

print(equation)
```

# Comparing the two models.
```{r}
# Comparison with likelihood ratio test 
lrtest(simple_model, complex_model_2)

# Comparison with ANOVA
anovaresults <- anova(simple_model, complex_model_2)
print(anovaresults)

# Creating a table with the regression results
library(stargazer)

regression_result <- stargazer(simple_model, complex_model_2, type = "text",
          title = "Regression Results",
          align = TRUE,
          ci = TRUE, 
          digit.types = list("pvalue" = 3), 
          report = "vcsp", 
          star.cutoffs = c(0.05, 0.01, 0.001), 
           add.lines=list(c("AIC", round(AIC(simple_model),1), round(AIC(complex_model_2),1))))

# Creating a table format for unstandardized regression coefficients, 95% confidence intervals, standardized regression coefficients (B and Beta values), and p values
library(broom)
library(lm.beta)

# Extracting statistics for the simpler model
simple_model_summary <- tidy(simple_model, conf.int = TRUE)
simple_model_beta <- lm.beta(simple_model)      

head(simple_model_summary)

simple_model_result <- simple_model_summary %>%
  mutate(Standardized_Beta = coef(simple_model_beta)) %>%
  dplyr::select(term, estimate, conf.low, conf.high, Standardized_Beta, p.value) %>%
  rename("B (Unstandardized)" = estimate,
         "Lower 95% CI" = conf.low,
         "Upper 95% CI" = conf.high,
         "Beta (Standardized)" = Standardized_Beta,
         "P-value" = p.value)

# Extracting statistics for the complex model
complex_model_summary <- tidy(complex_model_2, conf.int = TRUE)
complex_model_beta <- lm.beta(complex_model_2)

# Merging results for complex model
complex_model_result <- complex_model_summary %>%
  mutate(Standardized_Beta = coef(complex_model_beta)) %>%
  dplyr::select(term, estimate, conf.low, conf.high, Standardized_Beta, p.value) %>%
  rename("B (Unstandardized)" = estimate,
         "Lower 95% CI" = conf.low,
         "Upper 95% CI" = conf.high,
         "Beta (Standardized)" = Standardized_Beta,
         "P-value" = p.value)

# Printing results in table format
library(knitr)
cat("Simple Model Results:\n")
kable(simple_model_result, digits = 3, format = "markdown")

cat("\nComplex Model Results:\n")
kable(complex_model_result, digits = 3, format = "markdown")
```

The results of the analysis show that the complex model is a better fit for the data. This is based on the following results: 

- The results of AIC  are lower for the complex model (528.5), than the simpler model (572.5). 
- Based on adjusted R-squared, the complex model explains more variance in pain, that is 31.2%, than the simpler model, which explains about 7%. 
- In the simple model, only age is a significant predictor (Œ≤ = -0.084, 95%CI: -0.130, -0.039), p = 0.0004). 
- However, in the complex model, after adding psychological and hormone measures, age is no longer significant, while pain catastrophizing (Œ≤ = 0.083, 95% CI: 0.028, 0.139, p = 0.004) and cortisol serum (Œ≤ = 0.543, 95% CI: 0.299, 0.788, p < 0.000) have a positive, significant effect on pain. Other psychological variables, such as STAI_trait and mindfulness were not found significant. 

In conclusion, including the psychological and hormone measures in the model seem to provide value in explaining the variance in pain, which suggests that these measures influence the experience of pain and further research on them could give us more insight on the experience of pain. 

